{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmaxレイヤの実装\n",
    "\n",
    "前のセクションまでで乗算、加算、ReLU, Sigmoidといった計算レイヤの逆伝播を実装してきた。\n",
    "\n",
    "参考： https://sge.qiita.com/yoshinari_yuto/items/e07fc89c36e123a58b49\n",
    "\n",
    "このセクションからニューラルネットワークの逆伝播を実装していく。具体的には、行列の積（幾何学でアフィン変換とよばれる）における逆伝播を考える。\n",
    "\n",
    "### 5.6.1 Affineレイヤ\n",
    "\n",
    "ニューラルネットワークの順伝播は次のように実装した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(2) # 入力\n",
    "W = np.random.rand(2, 3) # 重み\n",
    "B = np.random.rand(3) # バイアス\n",
    "\n",
    "Y = np.dot(X, W) + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらにこのYは活性化関数によって変換され、次の層へ伝播される。\n",
    "\n",
    "これまでのように、ここで行った行列の積とバイアスの和を計算グラフで表してみる。\n",
    "\n",
    "図5-24\n",
    "\n",
    "この図は比較的単純なグラフだが、X, W, Bがスカラ値ではなく行列であることに注意して逆伝播を考えていく。\n",
    "\n",
    "最後のレイヤは単純に偏微分すれば良い。\n",
    "\n",
    "$$\n",
    "{\\bf Y} = (y_1, y_2, y_3), \\\\\n",
    "\\frac{\\partial L}{\\partial {\\bf Y}} =\n",
    "\\left ( \\frac{\\partial L}{\\partial y_1}, \\frac{\\partial L}{\\partial y_2}, \\frac{\\partial L}{\\partial y_3} \\right )\n",
    "$$\n",
    "\n",
    "次の加算レイヤの逆伝播はそのまま出力すればよかった。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial ({\\bf X} \\cdot {\\bf W})} = \\frac{\\partial L}{\\partial {\\bf Y}}, \\\\\n",
    "\\frac{\\partial L}{\\partial {\\bf B}} = \\frac{\\partial L}{\\partial {\\bf Y}}\n",
    "$$\n",
    "\n",
    "最後のAffineレイヤ (アフィン変換を行う処理) は\n",
    "\n",
    "$$\n",
    "f = {\\bf X} \\cdot {\\bf W}\\\\\n",
    "\\frac{\\partial L}{\\partial {\\bf X}} = \\frac{\\partial L}{\\partial f} \\cdot \\frac{\\partial f}{\\partial {\\bf X}} =\n",
    "\\frac{\\partial L}{\\partial ({\\bf X} \\cdot {\\bf W})} \\cdot \\frac{\\partial ({\\bf X} \\cdot {\\bf W})}{\\partial {\\bf X}}\n",
    "= \\frac{\\partial L}{\\partial {\\bf Y}} \\cdot {\\bf W}^{\\mathrm{T}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
